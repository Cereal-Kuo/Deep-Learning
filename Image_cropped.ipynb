{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whale & Dolphin Cropped Images\n",
    "* Version: 1.0\n",
    "* Creator: Eli Kuo\n",
    "* Environment: python 3.8.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility scripts for visualization of \"Happywhale - Whale and Dolphin Identification\" competition dataset, which is defined in the other [kernel](https://www.kaggle.com/code/acchiko/utility-functions-for-visualization-of-dataset). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libs import\n",
    "import utility_functions_for_visualization_of_dataset as myutils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines class for processing train/test images and metadata.\n",
    "class WhaleAndDolphin():\n",
    "    def __init__(self, path_to_metadata, path_to_dir_images, \\\n",
    "                 path_to_dir_nobg_images, path_to_dir_cropped_images):\n",
    "        self._path_to_metadata = path_to_metadata\n",
    "        self._path_to_dir_images = path_to_dir_images\n",
    "        self._path_to_dir_nobg_images = path_to_dir_nobg_images\n",
    "        self._path_to_dir_cropped_images = path_to_dir_cropped_images\n",
    "        \n",
    "        # Loads metadata to variable \"_metadata_all\"\n",
    "        self._metadata_all = pd.read_csv(path_to_metadata)\n",
    "        \n",
    "        # Adds several colmuns.\n",
    "        path_to_images = \\\n",
    "            [\"%s/%s\" % (path_to_dir_images, row.image) \\\n",
    "             for row in self._metadata_all.itertuples()]\n",
    "        self._metadata_all[\"path_to_image\"] = path_to_images\n",
    "        \n",
    "        path_to_nobg_images = \\\n",
    "            [\"%s/%s\" % (path_to_dir_nobg_images, row.image.replace(\".jpg\", \".png\")) \\\n",
    "             for row in self._metadata_all.itertuples()]\n",
    "        self._metadata_all[\"path_to_nobg_image\"] = path_to_nobg_images\n",
    "        \n",
    "        path_to_cropped_images = \\\n",
    "            [\"%s/%s\" % (path_to_dir_cropped_images, row.image.replace(\".jpg\", \".png\")) \\\n",
    "             for row in self._metadata_all.itertuples()]\n",
    "        self._metadata_all[\"path_to_cropped_image\"] = path_to_cropped_images\n",
    "        \n",
    "        annotations_xyxy = \\\n",
    "            [[] for row in self._metadata_all.itertuples()]\n",
    "        self._metadata_all[\"annotations_xyxy\"] = annotations_xyxy\n",
    "        \n",
    "        # Copies the metadata for processing it.\n",
    "        self._metadata = self._metadata_all.copy()\n",
    "        \n",
    "        self._all_species = self.getSpecies()\n",
    "        self._all_individual_ids = self.getIndividualIDs()\n",
    "        \n",
    "    def resetMetadata(self, initialize=False):\n",
    "        if hasattr(self, \"_metadata_tmp\") and not initialize:\n",
    "            self._metadata = self._metadata_tmp.copy()\n",
    "        else:\n",
    "            self._metadata = self._metadata_all.copy()\n",
    "            \n",
    "    def saveMetadataTemporary(self):\n",
    "        self._metadata_tmp = self._metadata.copy()\n",
    "        \n",
    "    def filterMetadata(self, query=\"index > -1\"):\n",
    "        sliced_metadata = \\\n",
    "            self._metadata.query(query).reset_index(drop=True)\n",
    "        self._metadata = sliced_metadata.copy()\n",
    "        \n",
    "    def filterMetadataBackgroundRemovedImageExistence(self):\n",
    "        indices = []\n",
    "        for row in self._metadata.itertuples():\n",
    "            if not os.path.exists(row.path_to_nobg_image):\n",
    "                indices.append(row.Index)\n",
    "                \n",
    "        sliced_metadata = self._metadata.drop(index=indices).reset_index(drop=True)\n",
    "        self._metadata = sliced_metadata.copy()\n",
    "        \n",
    "    def writeMetadata(self, path_to_metadata):\n",
    "        self._metadata.to_csv(path_to_metadata, index=False)\n",
    "        \n",
    "    def getMetadata(self):\n",
    "        return self._metadata\n",
    "    \n",
    "    def getSpecies(self):\n",
    "        return self._metadata[\"species\"].unique()\n",
    "    \n",
    "    def _species2id(self, species):\n",
    "        return np.where(self._all_species == species)[0][0]\n",
    "    \n",
    "    def getIndividualIDs(self):\n",
    "        return self._metadata[\"individual_id\"].unique()\n",
    "    \n",
    "    def showImagesTile(self, num_cols=4, draw_annotations=False):\n",
    "        metadata = self._metadata\n",
    "        titles = [row.image for row in metadata.itertuples()]\n",
    "        path_to_images = [row.path_to_image \\\n",
    "                          for row in metadata.itertuples()]\n",
    "        images = myutils.getImages(path_to_images)\n",
    "        if \"annotations_xyxy\" in metadata.columns and draw_annotations:\n",
    "            annotations_xyxy_for_images = [row.annotations_xyxy \\\n",
    "                                           for row in metadata.itertuples()]\n",
    "            texts_for_images = [[\"\" for _ in \\\n",
    "                                 range(len(row.annotations_xyxy))] \\\n",
    "                                 for row in metadata.itertuples()]\n",
    "            myutils.drawAnnotations( \\\n",
    "                images, \\\n",
    "                annotations_xyxy_for_images=annotations_xyxy_for_images, \\\n",
    "                texts_for_images=texts_for_images, \\\n",
    "                line_color=\"green\", line_width=3, text_color=\"green\" \\\n",
    "            )\n",
    "        myutils.showImagesTile(titles, images, num_cols=num_cols)\n",
    "        \n",
    "    def showProcessedImagesTile(self, num_cols=3, draw_annotations=False):\n",
    "        metadata = self._metadata\n",
    "        titles, path_to_images = [], []\n",
    "        for row in metadata.itertuples():\n",
    "            titles.append(\"%s (Org.)\" % row.image)\n",
    "            path_to_images.append(row.path_to_image)\n",
    "            \n",
    "            titles.append(\"%s (BG. removed)\" % row.image)\n",
    "            path_to_images.append(row.path_to_nobg_image)\n",
    "            \n",
    "            titles.append(\"%s (Cropped)\" % row.image)\n",
    "            path_to_images.append(row.path_to_cropped_image)\n",
    "        \n",
    "        images = myutils.getImages(path_to_images)\n",
    "        if \"annotations_xyxy\" in metadata.columns and draw_annotations:\n",
    "            annotations_xyxy_for_images = [row.annotations_xyxy \\\n",
    "                                           for row in metadata.itertuples()]\n",
    "            texts_for_images = [[\"\" for _ in \\\n",
    "                                 range(len(row.annotations_xyxy))] for row in metadata.itertuples()]\n",
    "            myutils.drawAnnotations(\n",
    "                images[::3],\n",
    "                annotations_xyxy_for_images=annotations_xyxy_for_images,\n",
    "                texts_for_images=texts_for_images, line_color=\"red\", line_width=3, text_color=\"red\" \n",
    "            ) # For only org. images.\n",
    "        myutils.showImagesTile(titles, images, num_cols=num_cols)\n",
    "        \n",
    "    def showIndividualImagesTile(self, num_cols=4, max_num_individual_images=4, max_num_individuals=10, draw_annotations=False):\n",
    "        self.saveMetadataTemporary()\n",
    "        \n",
    "        individual_ids = self.getIndividualIDs()\n",
    "        for individual_id in individual_ids[:max_num_individuals]:\n",
    "            print()\n",
    "            print(\"Individual ID : %s\" % individual_id)\n",
    "            self.filterMetadata(query=\"individual_id == \\\"%s\\\"\" % individual_id)\n",
    "            self.filterMetadata(query=\"index < %d\" % max_num_individual_images)\n",
    "            self.showImagesTile(num_cols=num_cols, draw_annotations=draw_annotations\n",
    "            )\n",
    "            self.resetMetadata()\n",
    "            \n",
    "    def removeBackground(self):\n",
    "        metadata = self._metadata\n",
    "        path_to_inputs = [row.path_to_image for row in metadata.itertuples()]\n",
    "        path_to_outputs = [row.path_to_nobg_image for row in metadata.itertuples()]\n",
    "        \n",
    "        for path_to_input, path_to_output in zip(path_to_inputs, path_to_outputs):\n",
    "            # Input to Output\n",
    "            !backgroundremover -i {path_to_input} -o {path_to_output}\n",
    "        \n",
    "    def calculateAnnotationsXyxy(self):\n",
    "        batch_size = 100\n",
    "        num_batches = len(self._metadata) // batch_size + 1\n",
    "        \n",
    "        for i_batch in range(num_batches):\n",
    "            i_start = i_batch * batch_size\n",
    "            i_end = i_start + batch_size\n",
    "            metadata = self._metadata.iloc[i_start:i_end]\n",
    "            \n",
    "            path_to_nobg_images = [row.path_to_nobg_image for row in metadata.itertuples()]\n",
    "            nobg_images = myutils.getImages(path_to_nobg_images)\n",
    "            ## fixed_images = [Image.eval(nobg_image, self._removeBugPixel) for nobg_image in nobg_images]\n",
    "            class_ids = [self._species2id(row.species) for row in metadata.itertuples()]\n",
    "            \n",
    "            annotations_xyxy = []\n",
    "            for nobg_image, class_id in zip(nobg_images, class_ids):\n",
    "                _, _, _, a = nobg_image.split()\n",
    "                x_min, y_min, x_max, y_max = a.getbbox() # Bounding box of non-zero alpha region\n",
    "                # confidence is for the further accuraccy attribute to annalysis \n",
    "                confidence = 1.0\n",
    "                annotation_xyxy = myutils._annotationXyxy(class_id, x_min, y_min, x_max, y_max, confidence)\n",
    "                annotations_xyxy.append([annotation_xyxy])\n",
    "                \n",
    "            self._metadata[\"annotations_xyxy\"].iloc[i_start:i_end] = annotations_xyxy\n",
    "    \n",
    "    #def _removeBugPixel(self, pixel_value):\n",
    "    #    if pixel_value == 1:\n",
    "    #        return 0\n",
    "    #    else:\n",
    "    #        return pixel_value\n",
    "        \n",
    "    def cropObject(self):\n",
    "        batch_size = 100\n",
    "        num_batches = len(self._metadata) // batch_size + 1\n",
    "        \n",
    "        for i_batch in range(num_batches):\n",
    "            i_start = i_batch * batch_size\n",
    "            i_end = i_start + batch_size\n",
    "            metadata = self._metadata.iloc[i_start:i_end]\n",
    "            \n",
    "            path_to_inputs = [row.path_to_image for row in metadata.itertuples()]\n",
    "            path_to_outputs = [row.path_to_cropped_image for row in metadata.itertuples()]\n",
    "            annotations_xyxy = [row.annotations_xyxy for row in metadata.itertuples()]\n",
    "            \n",
    "            for path_to_input, path_to_output, annotations_xyxy in zip(path_to_inputs, path_to_outputs, annotations_xyxy):\n",
    "                \n",
    "                image = Image.open(path_to_input)\n",
    "                annotation_xyxy = \\\n",
    "                    self._maxConfidenceAnnotation(annotations_xyxy)\n",
    "                x_min = annotation_xyxy[\"x_min\"]\n",
    "                y_min = annotation_xyxy[\"y_min\"]\n",
    "                x_max = annotation_xyxy[\"x_max\"]\n",
    "                y_max = annotation_xyxy[\"y_max\"]\n",
    "                image_cropped = image.crop((x_min, y_min, x_max, y_max))\n",
    "                image_cropped.save(path_to_output)\n",
    "            \n",
    "    def _maxConfidenceAnnotation(self, annotations_xyxy):\n",
    "        confidences = np.array([annotation_xyxy[\"confidence\"] for annotation_xyxy in annotations_xyxy])\n",
    "        index = np.argmax(confidences)\n",
    "        return annotations_xyxy[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outprint for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads metadata for train images.\n",
    "whale_and_dolphin = WhaleAndDolphin(\n",
    "    path_to_metadata = \"Data/train.csv\",\n",
    "    path_to_dir_images = \"Data/train_images\",\n",
    "    # No background\n",
    "    path_to_dir_nobg_images = \"Data/no_background/train_images\",\n",
    "    # Cropped images\n",
    "    path_to_dir_cropped_images = \"Data/cropped/train_images\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows train images for the first 3 individuals for each species.\n",
    "num_cols = 4\n",
    "max_num_individual_images = 4\n",
    "max_num_individuals = 3\n",
    "\n",
    "all_species = whale_and_dolphin.getSpecies()\n",
    "for i, species in enumerate(all_species):\n",
    "    whale_and_dolphin.filterMetadata(query=\"species == \\\"%s\\\"\" % species)\n",
    "    \n",
    "    print(\"\\n--------------------------------------------------\\n\")\n",
    "    print(\"\\n   Images for species No.%02d %s \\n\" % (i, species))\n",
    "    print(\"\\n--------------------------------------------------\\n\")\n",
    "    whale_and_dolphin.showIndividualImagesTile(\n",
    "        num_cols=num_cols,\n",
    "        max_num_individual_images=max_num_individual_images,\n",
    "        max_num_individuals=max_num_individuals\n",
    "    )\n",
    "    \n",
    "    whale_and_dolphin.resetMetadata(initialize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Romving Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "   Processing images for species No.00 melon_headed_whale\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "   Processing images for species No.01 humpback_whale\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "   Processing images for species No.02 false_killer_whale\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "   Processing images for species No.03 bottlenose_dolphin\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "   Processing images for species No.04 beluga\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "   Processing images for species No.05 minke_whale\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "   Processing images for species No.06 fin_whale\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "   Processing images for species No.07 blue_whale\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "   Processing images for species No.08 gray_whale\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "   Processing images for species No.09 southern_right_whale\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "   Processing images for species No.10 common_dolphin\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "   Processing images for species No.11 kiler_whale\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "   Processing images for species No.12 pilot_whale\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "   Processing images for species No.13 dusky_dolphin\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "   Processing images for species No.14 killer_whale\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "   Processing images for species No.15 long_finned_pilot_whale\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "   Processing images for species No.16 sei_whale\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "   Processing images for species No.17 spinner_dolphin\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "   Processing images for species No.18 bottlenose_dolpin\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "   Processing images for species No.19 cuviers_beaked_whale\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "   Processing images for species No.20 spotted_dolphin\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "   Processing images for species No.21 globis\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "   Processing images for species No.22 brydes_whale\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "   Processing images for species No.23 commersons_dolphin\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "   Processing images for species No.24 white_sided_dolphin\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "   Processing images for species No.25 short_finned_pilot_whale\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "   Processing images for species No.26 rough_toothed_dolphin\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "   Processing images for species No.27 pantropic_spotted_dolphin\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "   Processing images for species No.28 pygmy_killer_whale\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "   Processing images for species No.29 frasiers_dolphin\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Removes background. Limits number of processing images because of kaggle notebook limitation. Sets same number for each species as possible.\n",
    "num_images_per_species = int(4000 / len(all_species))\n",
    "i_start = 0\n",
    "i_end = i_start + num_images_per_species\n",
    "all_species = whale_and_dolphin.getSpecies()\n",
    "whale_and_dolphin.saveMetadataTemporary()\n",
    "\n",
    "for i, species in enumerate(all_species):\n",
    "   whale_and_dolphin.filterMetadata(query=\"species == \\\"%s\\\"\" % species)\n",
    "   whale_and_dolphin.filterMetadata(query=\"%d <= index < %d\" % (i_start, i_end))\n",
    "   print(\"\\n--------------------------------------------------\\n\")\n",
    "   print(\"\\n   Processing images for species No.%02d %s\\n\" % (i, species))\n",
    "   print(\"\\n--------------------------------------------------\\n\")\n",
    "   # whale_and_dolphin.removeBackground()\n",
    "   whale_and_dolphin.resetMetadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Adding Bounding Box\n",
    "Bounding box is cropped for future work (The model for identifing whale and dolphin may be created using the cropped images.) By using the background removing we are able to access the content of cropping content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates bounding box of object.\n",
    "whale_and_dolphin.calculateAnnotationsXyxy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>species</th>\n",
       "      <th>individual_id</th>\n",
       "      <th>path_to_image</th>\n",
       "      <th>path_to_nobg_image</th>\n",
       "      <th>path_to_cropped_image</th>\n",
       "      <th>annotations_xyxy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00021adfb725ed.jpg</td>\n",
       "      <td>melon_headed_whale</td>\n",
       "      <td>cadddb1636b9</td>\n",
       "      <td>Data/train_images/00021adfb725ed.jpg</td>\n",
       "      <td>Data/no_background/train_images/00021adfb725ed...</td>\n",
       "      <td>Data/cropped/train_images/00021adfb725ed.png</td>\n",
       "      <td>[{'class_id': 0, 'x_min': 0, 'y_min': 111, 'x_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000562241d384d.jpg</td>\n",
       "      <td>humpback_whale</td>\n",
       "      <td>1a71fbb72250</td>\n",
       "      <td>Data/train_images/000562241d384d.jpg</td>\n",
       "      <td>Data/no_background/train_images/000562241d384d...</td>\n",
       "      <td>Data/cropped/train_images/000562241d384d.png</td>\n",
       "      <td>[{'class_id': 1, 'x_min': 0, 'y_min': 139, 'x_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0007c33415ce37.jpg</td>\n",
       "      <td>false_killer_whale</td>\n",
       "      <td>60008f293a2b</td>\n",
       "      <td>Data/train_images/0007c33415ce37.jpg</td>\n",
       "      <td>Data/no_background/train_images/0007c33415ce37...</td>\n",
       "      <td>Data/cropped/train_images/0007c33415ce37.png</td>\n",
       "      <td>[{'class_id': 2, 'x_min': 0, 'y_min': 0, 'x_ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0007d9bca26a99.jpg</td>\n",
       "      <td>bottlenose_dolphin</td>\n",
       "      <td>4b00fe572063</td>\n",
       "      <td>Data/train_images/0007d9bca26a99.jpg</td>\n",
       "      <td>Data/no_background/train_images/0007d9bca26a99...</td>\n",
       "      <td>Data/cropped/train_images/0007d9bca26a99.png</td>\n",
       "      <td>[{'class_id': 3, 'x_min': 0, 'y_min': 79, 'x_m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00087baf5cef7a.jpg</td>\n",
       "      <td>humpback_whale</td>\n",
       "      <td>8e5253662392</td>\n",
       "      <td>Data/train_images/00087baf5cef7a.jpg</td>\n",
       "      <td>Data/no_background/train_images/00087baf5cef7a...</td>\n",
       "      <td>Data/cropped/train_images/00087baf5cef7a.png</td>\n",
       "      <td>[{'class_id': 1, 'x_min': 0, 'y_min': 1349, 'x...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                image             species individual_id  \\\n",
       "0  00021adfb725ed.jpg  melon_headed_whale  cadddb1636b9   \n",
       "1  000562241d384d.jpg      humpback_whale  1a71fbb72250   \n",
       "2  0007c33415ce37.jpg  false_killer_whale  60008f293a2b   \n",
       "3  0007d9bca26a99.jpg  bottlenose_dolphin  4b00fe572063   \n",
       "4  00087baf5cef7a.jpg      humpback_whale  8e5253662392   \n",
       "\n",
       "                          path_to_image  \\\n",
       "0  Data/train_images/00021adfb725ed.jpg   \n",
       "1  Data/train_images/000562241d384d.jpg   \n",
       "2  Data/train_images/0007c33415ce37.jpg   \n",
       "3  Data/train_images/0007d9bca26a99.jpg   \n",
       "4  Data/train_images/00087baf5cef7a.jpg   \n",
       "\n",
       "                                  path_to_nobg_image  \\\n",
       "0  Data/no_background/train_images/00021adfb725ed...   \n",
       "1  Data/no_background/train_images/000562241d384d...   \n",
       "2  Data/no_background/train_images/0007c33415ce37...   \n",
       "3  Data/no_background/train_images/0007d9bca26a99...   \n",
       "4  Data/no_background/train_images/00087baf5cef7a...   \n",
       "\n",
       "                          path_to_cropped_image  \\\n",
       "0  Data/cropped/train_images/00021adfb725ed.png   \n",
       "1  Data/cropped/train_images/000562241d384d.png   \n",
       "2  Data/cropped/train_images/0007c33415ce37.png   \n",
       "3  Data/cropped/train_images/0007d9bca26a99.png   \n",
       "4  Data/cropped/train_images/00087baf5cef7a.png   \n",
       "\n",
       "                                    annotations_xyxy  \n",
       "0  [{'class_id': 0, 'x_min': 0, 'y_min': 111, 'x_...  \n",
       "1  [{'class_id': 1, 'x_min': 0, 'y_min': 139, 'x_...  \n",
       "2  [{'class_id': 2, 'x_min': 0, 'y_min': 0, 'x_ma...  \n",
       "3  [{'class_id': 3, 'x_min': 0, 'y_min': 79, 'x_m...  \n",
       "4  [{'class_id': 1, 'x_min': 0, 'y_min': 1349, 'x...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filters metadata, which has background removed image.\n",
    "whale_and_dolphin.filterMetadataBackgroundRemovedImageExistence()\n",
    "metadata = whale_and_dolphin.getMetadata()\n",
    "# Then saves metadata as csv file.\n",
    "path_to_train_metadata = \"Data/train_with_annotation.csv\"\n",
    "whale_and_dolphin.writeMetadata(path_to_train_metadata)\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the total number of the files in the directory\n",
    "path, dirs, files = next(os.walk('Data/no_background/train_images'))\n",
    "num_images_train = len(files)\n",
    "i_start = 2 * num_images_train\n",
    "i_end = i_start + num_images_train\n",
    "# Locating the position\n",
    "whale_and_dolphin.filterMetadata(query=\"%d <= index < %d\" % (i_start, i_end))\n",
    "whale_and_dolphin.cropObject()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows first 100 processed images.\n",
    "num_images_per_batch = 100\n",
    "metadata = whale_and_dolphin.getMetadata()\n",
    "num_batches = int(len(metadata) / num_images_per_batch)\n",
    "max_num_batches = min(num_batches, 1)\n",
    "num_cols = 3\n",
    "\n",
    "whale_and_dolphin.saveMetadataTemporary()\n",
    "for i in range(max_num_batches):\n",
    "    i_start = i * num_images_per_batch\n",
    "    i_end = i_start + num_images_per_batch\n",
    "    whale_and_dolphin.showProcessedImagesTile(num_cols=num_cols, draw_annotations=True)\n",
    "    whale_and_dolphin.resetMetadata()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ed225720166559e7176d3793db16a2fd8d295f725007103b21ac3099d2a89ee8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
